[build-system]
requires = [ "setuptools>=61.0" ]
build-backend = "setuptools.build_meta"


[project]
name = "infer-client"
version = "0.0.3"
description = "Abstraction for AI Inference Client"
readme = "README.md"
keywords = [ "infer-client", "onnxruntime", "onnxruntime-gpu", "tritonclient" ]
authors = [
    { name = "Dao Quang Duy", email = "duydaoquang12@gmail.com" },
]
maintainers = [
    { name = "Rabiloo Developers", email = "oss@rabiloo.com" },
]
license = {text = "The MIT License"}
requires-python = ">=3.10"
classifiers = [
    "Programming Language :: Python :: 3",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Development Status :: 2 - Pre-Alpha",
]
dependencies = [
    "numpy"
]

[project.optional-dependencies]
dev = [
    "black",
    "flake8",
    "flake8-pyproject",
    "pytest",
    "typing_extensions"
]
onnxruntime = [
    "onnxruntime"
]
onnxruntime-gpu = [
    "onnxruntime-gpu"
]
tritonclient = [
    "tritonclient[grpc]"
]

[project.urls]
"Homepage" = "https://github.com/rabiloo/python-infer-client"
"Repository" = "https://github.com/rabiloo/python-infer-client"
"Bug Tracker" = "https://github.com/rabiloo/python-infer-client/issues"


[tool.flake8]
count = true
max-complexity = 10
max-line-length = 120
statistics = true
ignore = ["W503"]


[tool.black]
target-version = ["py310"]
line-length = 120


[tool.isort]
profile = "black"
lines_between_types = 1
line_length = 120
